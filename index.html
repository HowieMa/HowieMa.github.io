
<html>
<head>
  <meta content="text/html; charset=utf-8" http-equiv="Content-Type" />
  <title>Haoyu Ma, UCI</title>
  <link rel="shortcut icon" href="logo.jpg">
  <meta content="Haoyu Ma, howiema.github.io" name="keywords" />
  <style media="screen" type="text/css">html, body, div, span, applet, object, iframe, h1, h2, h3, h4, h5, h6, p, blockquote, pre, a, abbr, acronym, address, big, cite, code, del, dfn, em, font, img, ins, kbd, q, s, samp, small, strike, strong, sub, tt, var, dl, dt, dd, ol, ul, li, fieldset, form, label, legend, table, caption, tbody, tfoot, thead, tr, th, td {
  border: 0pt none;
  font-family: inherit;
  font-size: 100%;
  font-style: inherit;
  font-weight: inherit;
  margin: 0pt;
  outline-color: invert;
  outline-style: none;
  outline-width: 0pt;
  padding: 0pt;
  vertical-align: baseline;
}

a {
  color: #1772d0;
  text-decoration:none;
}

a:focus, a:hover {
  color: #f09228;
  text-decoration:none;
}

a.paper {
  font-weight: bold;
  font-size: 12pt;
}

b.paper {
  font-weight: bold;
  font-size: 12pt;
}

* {
  margin: 0pt;
  padding: 0pt;
}

body {
  position: relative;
  margin: 3em auto 2em auto;
  width: 800px;
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 14px;
  background: #eee;
}

h2 {
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 15pt;
  font-weight: 700;
}

h3 {
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 16px;
  font-weight: 700;
}

strong {
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 13px;
  font-weight:bold;
}

ul {
  list-style: circle;
}

img {
  border: none;
}

li {
  padding-bottom: 0.5em;
  margin-left: 1.4em;
}

alert {
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 13px;
  font-weight: bold;
  color: #FF0000;
}

em, i {
  font-style:italic;
}

div.section {
  clear: both;
  margin-bottom: 1.5em;
  background: #eee;
}

div.spanner {
  clear: both;
}

div.paper {
  clear: both;
  margin-top: 0.5em;
  margin-bottom: 1em;
  border: 1px solid #ddd;
  background: #fff;
  padding: 1em 1em 1em 1em;
}

div.paper div {
  padding-left: 230px;
}

img.paper {
  margin-bottom: 0.5em;
  float: left;
  width: 200px;
}

span.blurb {
  font-style:italic;
  display:block;
  margin-top:0.75em;
  margin-bottom:0.5em;
}

pre, code {
  font-family: 'Lucida Console', 'Andale Mono', 'Courier', monospaced;
  margin: 1em 0;
  padding: 0;
}

div.paper pre {
  font-size: 0.9em;
}
</style>

<link href="http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic" rel="stylesheet" type="text/css" /><!--<link href='http://fonts.googleapis.com/css?family=Open+Sans+Condensed:300' rel='stylesheet' type='text/css'>--><!--<link href='http://fonts.googleapis.com/css?family=Open+Sans' rel='stylesheet' type='text/css'>--><!--<link href='http://fonts.googleapis.com/css?family=Yanone+Kaffeesatz' rel='stylesheet' type='text/css'>-->
</head>
<!-- <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-45959174-3', 'ho.github.io');
  ga('send', 'pageview');

</script>
-->

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-66888300-1', 'auto');
  ga('send', 'pageview');

</script>
<body>
<div style="margin-bottom: 1em; border: 1px solid #ddd; background-color: #fff; padding: 1em; height: 180px;">
<div style="margin: 0px auto; width: 100%;">
<img title="Haoyu Ma" style="float: left; padding-left: .01em; padding-right: .01em; height: 150px;" src="profile2.jpg" />
<div style="padding-left: 10em; vertical-align: top; height: 150px;"><span style="line-height: 150%; font-size: 20pt;">Haoyu Ma </span><br />
<span>Research Scientist @GenAI, Meta </span> <br/>
<!-- <span>Computer Science Ph.D @ University of California, Irvine </span><br /> -->
<span></span><br/>
<span><strong>Email  </strong>: haoyum3 [at] uci [dot] edu</span> <br />
<!-- <span><strong>Office </strong>: DBH 4069, Irvine, CA, 92617  </span><br />  -->

<span></span><br/>
<p>
    <a href='https://github.com/HowieMa'><img src="img/git.jpg" height='20px' /></a>
    <a href='https://scholar.google.com/citations?user=8jugwosAAAAJ&hl=en'><img src="img/gs.jpg" height='20px' /></a>
    <a href='https://www.linkedin.com/in/haoyu-ma-53517915a/'><img src="img/in.jfif" height='20px' /></a>
    <!-- <a href='https://www.zhihu.com/people/ma-hao-yu-99/'><img src="img/zh.jpg" height='20px' /></a> -->
</p>
</div>
</div>
</div>


<!-- ************************************ About Me ************************************ -->

<div style="clear: both;">
<div class="section">
<h2>About Me   <!-- <a href = 'cv/Personal_Resume.pdf'>[CV] </a> -->
<!-- (<a href=''>CV</a>) (<a href=''>Google Scholar</a>)  -->

</h2>  
<div class="paper">
I am a Research Scientist at GenAI, Meta. Previously, I obtained my PhD degree from  <a href = 'http://www.ics.uci.edu/'>Donald Bren School of Information and Computer Sciences</a>,  UC Irvine in 2024, supervised by <a href='http://www.ics.uci.edu/~xhx/'>Prof. Xiaohui Xie</a>. I obtained my B.Eng degree from <a href='https://www.seu.edu.cn/english'>Southeast University (SEU) </a>, Nanjing, China in 2019. 
<br></br>
My research interests are deep learning and computer vision. 

</div>
</div>
</div>

<!-- ************************************ News ************************************ -->

<div style="clear: both;">
<div class="section">
  <h2>News</h2>
  <div class="paper">
    <ul>
    <li> 07/2024: We launched  <a href='https://ai.meta.com/research/publications/imagine-yourself-tuning-free-personalized-image-generation/'>Imagine Yourself</a>. Try it in IG, Messenger, and <a href='https://meta.ai'>meta.ai</a>
    <li> 03/2024: I joined GenAI, Meta as a research scientist </li>
    <li> 03/2024: I earned my PhD degree from University California, Irvine </li>
    <li> 02/2024: Two papers are accepted by CVPR 2024. </li>
    <li> 11/2023: One paper is accepted by CPAL 2024. </li>
    <li> 10/2023: Three papers are accepted by WACV 2024. </li>
    <li> 11/2022: One paper is accepted by AAAI 2023. </li>	    
    <li> 07/2022: Two papers are accepted by ECCV 2022. </li>
    <li> 05/2022: One paper is accepted by ICML 2022. </li>
    <li> 03/2022: One paper is accepted by ICLR-PAIR2Struct 2022. </li>
    <li> 03/2022: One paper is accepted by CVPR 2022. </li>
    <li> 10/2021: One paper is accepted by BMVC 2021. </li>
    <li> 05/2021: One paper is accepted by KDD 2021. </li>
    <li> 01/2021: One paper is accepted by ICLR 2021 (Spotlight). </li>
    <li> 08/2020: One paper is accepted by BMVC 2020 (Oral).</li>
    <li> 11/2019: Two papers are accepted by WACV 2020.</li>
    <!--<li> 07/2019: One paper is accepted by BMVC 2019.</li>  -->
    <!--<li> 06/21/2019: Received Bachelor degree from Southeast University.</li>  -->
    </ul>
  </div>
</div>
</div>


<!-- ************************************ Publications ************************************ -->
<div style="clear: both;">
<div class="section">
<!-- <h2 id="confpapers">Selected Publications [ <a href='Publications.html'>Full List</a> ]</h2>   -->

<h2 id="confpapers">Selected Publications [<a href='https://scholar.google.com/citations?user=8jugwosAAAAJ&hl=en'>Full List</a>] </h2>


<div class="paper" id="hrbp"><img class="paper" src="papers/maskint.png" title="" />
<div> <strong>MaskINT: Video Editing via Interpolative Non-autoregressive Masked Transformers</strong><br />
<strong>H. Ma</strong>, S. Mahdizadehaghdam, B. Wu, Z. Fan, Y. Gu, Z. Zhao, L. Shapira and X. Xie <br />
Computer Vision and Pattern Recognition Conference (<strong>CVPR</strong>), 2024.  <br />
[ <a href='https://arxiv.org/pdf/2312.12468.pdf'>Paper</a> ] [ <a href='https://maskint.github.io/'>Project Page</a> ]
</div>
<div class="spanner"></div>
</div>


<div class="paper" id="hrbp"><img class="paper" src="papers/cpal-hrbp-teaser.png" title="" />
<div> <strong>HRBP: Hardware-friendly Regrouping towards Block-based Pruning for Sparse CNN Training</strong><br />
<strong>H. Ma</strong>, C. Zhang, L. Xiang, X. Ma, G. Yuan, W. Zhang, S. Liu, T. Chen, D. Tao, Y. Wang, Z. Wang, and X. Xie <br />
Conference on Parsimony and Learning (<strong>CPAL</strong>), 2024.  <br />
[ <a href='https://openreview.net/forum?id=VP1Xrdz0Bp'>Paper</a> ] [ <a href='https://github.com/HowieMa/HRBP-pruning'>Code</a> ] [ <a href="papers/cpal-slides.pdf">Slides</a> ]
</div>
<div class="spanner"></div>
</div>


<div class="paper" id="cvthead"><img class="paper" src="papers/wacv24-216-teaser.png" title="" />
<div> <strong>CVTHead: One-shot Controllable Head Avatar with Vertex-feature Transformer</strong><br />
<strong>H. Ma</strong>, T. Zhang, S. Sun, X. Yan, K. Han, and X. Xie <br />
IEEE Winter Conference on Applications of Computer Vision (<strong>WACV</strong>), 2024.  <br />
[ <a href='https://arxiv.org/pdf/2311.06443.pdf'>Paper</a> ] [ <a href='https://github.com/HowieMa/CVTHead'>Code</a> ] [ <a href="papers/wacv24-216-poster.pdf">Poster</a> ] [ <a href="papers/wacv24-216-slides.pdf">Slides</a> ]
</div>
<div class="spanner"></div>
</div>


<div class="paper" id="lfd"><img class="paper" src="papers/lfd-teaser.png" title="" />
<div> <strong>Light Field Diffusion for Single-View Novel View Synthesis</strong><br />
Y. Xiong, <strong>H. Ma</strong>, S. Sun, K. Han, H. Tang, and X. Xie <br />
Arxiv Preprint, 2023.  <br />
[ <a href='https://arxiv.org/pdf/2309.11525.pdf'>Paper</a> ] [ <a href="https://lightfielddiffusion.github.io/">Project Page</a> ]
</div>
<div class="spanner"></div>
</div>



<div class="paper" id="aaai"><img class="paper" src="papers/AAAI23.png" title="" />
<div> <strong>Peeling the Onion: Hierarchical Reduction of Data Redundancy for Efficient Vision Transformer Training</strong><br />
Z. Kong*, <strong>H. Ma*</strong>, G. Yuan*, M. Sun, Y. Xie, P. Dong, X. Meng, X. Shen, H. Tang, M. Qin, T. Chen, X. Ma, X. Xie, Z. Wang, and Y. Wang <br />
Thirty-Seventh AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>), 2023.  <br />
[ <a href='https://arxiv.org/pdf/2211.10801.pdf'>Paper</a> ] [ <a href="https://github.com/ZLKong/Tri-Level-ViT">Code</a> ]
</div>
<div class="spanner"></div>
</div>




<div class="paper" id="ppt"><img class="paper" src="papers/eccv_ppt.jpg" title="" />
<div> <strong>PPT: token-Pruned Pose Transformer for monocular and multi-view human pose estimation</strong><br />
<strong>H. Ma</strong>, Z. Wang, Y. Chen, D. Kong, L. Chen, X. Liu, X. Yan, H. Tang, and X. Xie <br />
European Conference on Computer Vision (<strong>ECCV</strong>), 2022.  <br />
[ <a href='https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136650416.pdf'>Paper</a> ] [ <a href="https://github.com/HowieMa/PPT">Code</a> ] [ <a href="papers/0046.pdf">Poster</a> ] 
</div>
<div class="spanner"></div>
</div>




<div class="paper" id="ppt"><img class="paper" src="papers/sparse_mask.jpg" title="" />
<div> <strong>Training Your Sparse Neural Network Better with Any Mask </strong><br />
A. Jaiswal, <strong>H. Ma</strong>, T. Chen, Y. Ding, and Z. Wang <br />
International Conference on Machine Learning (<strong>ICML</strong>), 2022.  <br />
[ <a href='https://proceedings.mlr.press/v162/jaiswal22a/jaiswal22a.pdf'>Paper</a> ] [ <a href='https://github.com/VITA-Group/ToST'>Code</a> ]
</div>
<div class="spanner"></div>
</div>



<div class="paper" id="eiclip"><img class="paper" src="papers/cvpr_eiclip.jpg" title="" />
<div> <strong>EI-CLIP: Entity-aware Interventional Contrastive Learning for E-commerce Cross-modal Retrieval</strong><br />
<strong>H. Ma</strong>, H. Zhao, Z. Lin, A. Kale, Z. Wang, T. Yu, J. Gu, S. Choudhary, and X. Xie <br />
Computer Vision and Pattern Recognition Conference (<strong>CVPR</strong>), 2022.  <br />
[ <a href='https://openaccess.thecvf.com/content/CVPR2022/papers/Ma_EI-CLIP_Entity-Aware_Interventional_Contrastive_Learning_for_E-Commerce_Cross-Modal_Retrieval_CVPR_2022_paper.pdf'>Paper</a> ] [ <a href='papers/cvpr22_eiclip_poster.pdf'>Poster</a> ]
</div>
<div class="spanner"></div>
</div>



<div class="paper" id="stingy"><img class="paper" src="papers/stingy.png" title="" />
<div> <strong>Sparse Logits Suffice to Fail Knowledge Distillation</strong><br />
<strong>H. Ma</strong>, Y. Huang. H. Tang, C. You, D. Kong, and X. Xie <br />
International Conference on Learning Representations (<strong>ICLR</strong>)  Workshop on PAIR^2Struct, 2022  <br />
[ <a href='https://openreview.net/pdf?id=BxZgduuNDl5'>Paper</a> ] [ <a href='https://github.com/HowieMa/stingy-teacher'>Code</a> ] [ <a href='papers/stingy.pdf'>Poster</a> ]
</div>
<div class="spanner"></div>
</div>



<div class="paper" id="transfusion"><img class="paper" src="papers/transfusion.jpg" title="" />
<div> <strong>TransFusion: Cross-view Fusion with Transformer for 3D Human Pose Estimation</strong><br />
<strong>H. Ma</strong>, L. chen, D. Kong, Z. Wang, X. Liu, H. Tang, X. Yan, Y. Xie, S. Lin, and X. Xie <br />
British Machine Vision Virtual Conference (<strong>BMVC</strong>), 2021.  <br />
[ <a href='https://arxiv.org/pdf/2110.09554.pdf'>Paper</a> ] [ <a href='https://github.com/HowieMa/TransFusion-Pose'>Code</a> ] [ <a href='https://www.bmvc2021-virtualconference.com/conference/papers/paper_0016.html'>Presentation</a> ] [ <a href='papers/bmvc21_transfusion_slides.pdf'>Slides</a> ]
</div>
<div class="spanner"></div>
</div>




<div class="paper" id="pdnet"><img class="paper" src="papers/pdnet.jpg" title="" />
<div> <strong>PD-Net: Quantitative Motor Function Evaluation for Parkinson's Disease via Automated Hand Gesture Analysis</strong><br />
Y. Chen, <strong>H. Ma</strong>, J. Wang, J. Wu, X. Wu, and X. Xie <br />
Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (<strong>KDD</strong>), 2021.  <br />
[ <a href='https://dl.acm.org/doi/abs/10.1145/3447548.3467130'>Paper</a> ]
</div>
<div class="spanner"></div>
</div>





<div class="paper" id="nasty"><img class="paper" src="papers/nasty.png" title="Undistillable: Making A Nasty Teacher That CANNOT Teach Students" />
<div> <strong>Undistillable: Making A Nasty Teacher That CANNOT Teach Students</strong><br />
<strong>H. Ma</strong>, T. Chen, T. Hu, C. You, X. Xie, and Z. Wang <br />
International Conference on Learning Representations (<strong>ICLR</strong>), 2021. <font color="red">(Spotlight)</font>  <br />
[ <a href='https://openreview.net/pdf?id=0zvfm-nZqQs'>Paper</a> ] [ <a href='https://github.com/VITA-Group/Nasty-Teacher'>Code</a> ] [ <a href='https://iclr.cc/virtual/2021/spotlight/3446'>Presentation</a> ] [ <a href='papers/nasty_teacher_slides.pdf'>Slides</a> ] [ <a href='papers/nasty_teacher_poster.pdf'>Poster</a> ]

</div>
<div class="spanner"></div>
</div>



<div class="paper" id="siagcn"><img class="paper" src="papers/siagcn.png" title="SIA-GCN: A Spatial Information Aware Graph Neural Network with 2D Convolutions for Hand Pose Estimation" />
<div><strong>SIA-GCN: A Spatial Information Aware Graph Neural Network with 2D Convolutions for Hand Pose Estimation</strong><br />
D. Kong, <strong>H. Ma</strong> and X. Xie<br />
British Machine Vision Virtual Conference (<strong>BMVC</strong>), 2020. <font color="red">(Oral)</font> <br />
[ <a href='https://www.bmvc2020-conference.com/assets/papers/0066.pdf'>Paper</a> ]
</div>
<div class="spanner"></div>
</div>




<div class="paper" id="nsrm_hand"><img class="paper" src="papers/nsrm.png" title="Nonparametric Structure Regularization Machine for 2D Hand Pose Estimation" />
<div> <strong>Nonparametric Structure Regularization Machine for 2D Hand Pose Estimation</strong><br />
Y. Chen*, <strong>H. Ma*</strong>, D. Kong, X. Yan, J. Wu, W. Fan, and X. Xie<br />
IEEE Winter Conference on Applications of Computer Vision (<strong>WACV</strong>), 2020. <br />
[ <a href='https://arxiv.org/pdf/2001.08869.pdf'>Paper</a>  ] [ <a href='https://github.com/HowieMa/NSRMhand'>Code</a> ] [ <a href='https://www.youtube.com/watch?v=_4n09Dv-HgE&t=2192s'>Presentation </a> ] [ <a href='papers/wacv20_nsrm_slides.pdf'>Slides</a> ] [ <a href='papers/wacv962poster.pdf'>Poster</a> ] <br />
</div>
<div class="spanner"></div>
</div>



<!--
<div class="paper" id="rmn_hand"><img class="paper" src="papers/rmn.png" title="Rotation-invariant Mixed Graphical Model Network
for 2D Hand Pose Estimation" />
<div> <strong>Rotation-invariant Mixed Graphical Model Network for 2D Hand Pose Estimation</strong><br />
D. Kong, <strong>H. Ma</strong>, Y. Chen, and X. Xie<br />
IEEE Winter Conference on Applications of Computer Vision (<strong>WACV</strong>), 2020. <br />
[ <a href='https://arxiv.org/pdf/2002.02033.pdf'>Paper</a>  ] [ <a href='papers/wacv767poster.pdf'>Poster</a> ] <br />
</div>
<div class="spanner"></div>
</div>


<div class="paper" id="agm"><img class="paper" src="papers/bmvc_2019.png" title="Adaptive Graphical Model Network for 2D Handpose Estimation" />
<div> <strong>Adaptive Graphical Model Network for 2D Handpose Estimation</strong><br />
D. Kong, Y. Chen, <strong>H. Ma</strong>, X. Yan, and X. Xie<br />
British Machine Vision Conference (<strong>BMVC</strong>), 2019. <br />
[ <a href='https://bmvc2019.org/wp-content/uploads/papers/0907-paper.pdf'>Paper</a>  ]  <br />
</div>
<div class="spanner"></div>
</div>
-->


<div class="paper" id="lstmunet"><img class="paper" src="papers/icivc.png" title="LSTM Multi-modal UNet for Brain Tumor Segmentation" />
<div> <strong>LSTM Multi-modal UNet for Brain Tumor Segmentation</strong><br />
F. Xu, <strong>H. Ma</strong>, J. Sun, R. Wu, X. Liu, and Y. Kong<br />
IEEE Conference on Image, Vision and Computing(<strong>ICIVC</strong>), 2019. <br />
[ <a href='https://ieeexplore.ieee.org/document/8981027'>Paper</a> ] [ <a href='papers/slides_icivc.pdf'>Slides</a>  ] [ <a href='https://github.com/HowieMa/lstm_multi_modal_UNet'>Code</a> ] <br />
</div>
<div class="spanner"></div>
</div>


<!--

<div class="paper" id="brain_par"><img class="paper" src="papers/brain_par.png" title="Multi-Session Parcellation of the Human Brain Using Resting-State fMRI" />
<div> <strong>Multi-Session Parcellation of the Human Brain Using Resting-State fMRI</strong><br />
<strong>H. Ma</strong>, R. Lei, J. Sun, and Y. Kong <br />
IEEE  Conference on Computer Supported Cooperative Work in Design (<strong>CSCWD</strong>), 2018. <br />
[ <a href='https://ieeexplore.ieee.org/document/8465192'>Paper</a> ]  <br />
</div>
<div class="spanner"></div>
</div>

-->


</div>
</div>


<!-- ************************************ Academic Service ************************************ -->
<div style="clear: both;">
<div class="section">
<h2 id="confpapers">Academic Service</h2>
<div class="paper">
<ul>

<strong>Conference Reviewer</strong> <br>
<p> CVPR2024, ICML2024, ECCV2024, ICLR2024, CPAL2024, WACV2024</p>
<p> CVPR2023, ICML2023, ICCV2023, NeurIPS2023</p>
<p> CVPR2022, ICML2022, ECCV2022, NeurIPS2022, WACV2022, BMVC2022 </p>
<p> BMVC2021 </p>
</ul>
</div> 

<div class="paper">
<strong>TA/Readers: </strong> <br>
<p> COMPSCI 271/171, Introduction to Artificial Intelligence (2020-2024)</p>
<p> COMPSCI 274C, Neural Networks and Deep Learning (2021,2023) </p>
<p> COMPSCI 178, Machine Learning & Data Mining (2020)</p>


</div>
</div>
</div>


<!-- ************************************ Presentation ************************************ -->
<!--
<div style="clear: both;">
<div class="section">
<h2 id="confpapers">Presentation/Talk</h2>
<div class="paper">
<ul>
<li></li>

</ul>
<div class="spanner"></div>
</div>
</div>
</div>
-->


<!-- ************************************ Contests ************************************ -->

<div style="clear: both;">
<div class="section">
<h2 id="confpapers">Contests</h2>
<div class="paper">
<ul>
 <li><strong>Kaggle <a href='https://www.kaggle.com/c/pku-autonomous-driving/leaderboard'>Peking University/Baidu - Autonomous Driving</a></strong>, <strong>Rank</strong>: 52/866(Top 6%), Bronze medal </li> 

</ul>

<div class="spanner"></div>
</div>
</div>
</div>


<!-- ************************************ Awards ************************************ -->
<div style="clear: both;">
<div class="section"><h2>Awards</h2>
<div class="paper">
<li><strong>WACV 2024 Doctor Consortium</li>
<li><strong>Dean's Awards from Donald Bren School of Information and Computer Sciences, 2019</li>
<li><strong>Merit Student, 2016/2017</li>
<li><strong>National Scholarship, 2016</li>
</div>
</div>
</div>


<!-- ************************************ MISC ************************************ -->
<!--
<div style="clear: both;">
<div class="section">
<h2 id="confpapers">Misc</h2>
<div class="paper">
<ul>
<li><strong>Zhihu: <a href='https://www.zhihu.com/people/ma-hao-yu-99/activities'>Home link</a></strong> </li>

</ul>
<div class="spanner"></div>
</div>
</div>
</div>
--> 


<!-- Friends **************************************************** -->
<!--
<div style="clear: both;">
<div class="section"><h2>Friends && Collaborators</h2>
<div class="paper">
<a href=''>
<a href='https://zyy0721.github.io/'>Yiyu Zhang</a> (NJU),

</div>
</div>
</div>

-->

<div style="clear:both;">
<p align="right"><font size="5">Published with <a href='https://pages.github.com/'>GitHub Pages</a></font></p>
</div>

<hr>

<script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?&t=tt&d=AE9F0wbFUGav5CsUlkqOSVucLiTXxuvkC8jErk-oS_I&cl=ffffff&w=300"></script>


</body>
</html>
